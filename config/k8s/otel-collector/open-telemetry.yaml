apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: simplest
  namespace: monitoring
spec:
  image: otel/opentelemetry-collector-contrib-dev:latest
  serviceAccount: otelcontribcol
  mode: daemonset
  hostNetwork: true
  ports:
    - name: http
      port: 9090
      targetPort: 9090
      protocol: TCP
    - name: grpc
      port: 4317
      targetPort: 4317
      protocol: TCP
  env:
    - name: K8S_NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
  config:
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318
      prometheus:
        config:
          scrape_configs:
            - job_name: 'k8s-metrics'
              kubernetes_sd_configs:
                - role: pod
              relabel_configs:
                - source_labels: [__meta_kubernetes_pod_label_app]
                  action: keep
                  regex: fitme
      hostmetrics:
        collection_interval: 30s
        scrapers:
          cpu: {}
          memory: {}
          load:
            cpu_average: true
      k8s_cluster:
        collection_interval: 10s
        node_conditions_to_report: [Ready, MemoryPressure, DiskPressure, NetworkUnavailable]
        allocatable_types_to_report: [cpu, memory, storage]
      k8s_events:
        auth_type: serviceAccount
    processors:
      batch:
        send_batch_max_size: 1000
        timeout: 30s
        send_batch_size: 800
      memory_limiter:
        check_interval: 1s
        limit_percentage: 70
        spike_limit_percentage: 30
      metricstransform:
        transforms:
          include: .+
          match_type: regexp
          action: update
          operations:
            - action: add_label
              new_label: kubernetes.cluster.id
              new_value: CLUSTER_ID_TO_REPLACE
            - action: add_label
              new_label: kubernetes.name
              new_value: CLUSTER_NAME_TO_REPLACE
      k8sattributes:
        auth_type: serviceAccount
        passthrough: false
        extract:
          metadata:
            - k8s.pod.name
            - k8s.namespace.name
            - k8s.node.name
    exporters:
      prometheus:
        #endpoint: "localhost:9090"
        endpoint: "http://prometheus-kube-prometheus-prometheus.monitoring.svc.cluster.local:9090/metrics"
      loki:
        endpoint: http://loki.monitoring.svc.cluster.local:3100/loki/api/v1/push
        labels:
          resource:
            container.name: "container_name"
            k8s.cluster.name: "k8s_cluster_name"
          attributes:
            k8s.event.reason: "k8s_event_reason"
      otlp:
        endpoint: tempo.monitoring.svc.cluster.local:4317
      logging:
        loglevel: debug
    extensions:
      memory_ballast:
        size_in_percentage: 20
    service:
      pipelines:
        metrics:
          receivers: [prometheus, hostmetrics]
          processors: [memory_limiter, metricstransform, k8sattributes, batch]
          exporters: [prometheus]
        logs:
          receivers: [k8s_events]
          processors: [memory_limiter, k8sattributes, batch]
          exporters: [loki, logging]
        traces:
          receivers: [otlp]
          processors: [batch]
          exporters: [otlp]
